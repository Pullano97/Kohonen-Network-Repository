"""
---------------------
This program performs four phases for the Ising spin-1 model with D=2:
1) It generates a dataset of 25×25 configurations thermalized at random temperatures in [0, tmax].
   For each configuration, the average magnetization is computed:
       m(S) = (1/N) Σ s_i,  with s_i ∈ {-1, 0, +1}.
   A scatter plot (m vs. T) and a heatmap of one lattice configuration are displayed.
2) It trains a Self-Organizing Map (SOM 15×15) using the batch method.
3) It generates test signals at fixed temperatures. The list of 170 fixed temperatures is manually defined,
   for example: from 0 to 0.3 in steps of 0.1, from 0.3 to 0.5 in steps of 0.005, from 0.5 to 5 in steps of 0.1,
   from 5 to 10 in steps of 0.2, from 10 to 20 in steps of 0.5.
4) For each signal, it computes the number of distinct neurons (unique BMUs) activated by the SOM and plots
   the graph "activated neurons vs. Temperature".

In the regime with D=2 the model shows a first-order transition around \(T_c \approx 0.4\).
"""

import random
import math
import time
import matplotlib.pyplot as plt
import numpy as np

# ------------------------------
# FUNCTIONS FOR GENERATING THE ISING SPIN-1 DATASET (D=2)
# ------------------------------

def intro():
    print("This program generates 25×25 Ising spin-1 configurations thermalized at random temperatures for training")
    print("and test signals at fixed temperatures (170 temperatures defined manually, 300 configurations each).")
    print("Phase 1: 10,000 configurations at T ∈ [0, tmax] for training (scatter plot of m vs. T and a heatmap).")
    print("Phase 2: Training of a SOM (15×15) using the batch method.")
    print("Phase 3: Generation of test signals at fixed temperatures (manually defined list).")
    print("Phase 4: Plotting the number of activated (unique BMU) neurons vs. Temperature.")
    print("For D=2 the transition (first-order) occurs around T ≈ 0.4.\n")

def rand_val():
    return random.random()

def spin1():
    # Returns -1, 0, or +1 (equal probability)
    return random.choice([-1, 0, 1])

def fill_lattices(lattices, n, N, M):
    for instance in range(n):
        for i in range(N):
            for j in range(M):
                lattices[instance][i][j] = spin1()

def assign_temperatures(T, n, tmax):
    for i in range(n):
        T[i] = rand_val() * tmax

def boundaries(Plus, Minus, N):
    for i in range(N):
        Plus[i] = i + 1
        Minus[i] = i - 1
    Plus[N - 1] = 0
    Minus[0] = N - 1

def metropolis(lattices, Plus, Minus, T, n, N, M, Steps, J, D):
    # Here D is fixed to 2
    for instance in range(n):
        beta = 1.0 / T[instance] if T[instance] > 0 else 1.0
        for sweep in range(Steps):
            for i in range(N):
                for j in range(M):
                    current_spin = lattices[instance][i][j]
                    possibilities = [-1, 0, 1]
                    possibilities.remove(current_spin)
                    new_spin = random.choice(possibilities)
                    
                    dx = lattices[instance][Plus[i]][j]
                    sx = lattices[instance][Minus[i]][j]
                    up = lattices[instance][i][Minus[j]]
                    down = lattices[instance][i][Plus[j]]
                    total_neighbors = dx + sx + up + down
                    
                    deltaE = -J * (new_spin - current_spin) * total_neighbors + D * (new_spin**2 - current_spin**2)
                    
                    if deltaE <= 0:
                        lattices[instance][i][j] = new_spin
                    else:
                        if rand_val() < math.exp(-beta * deltaE):
                            lattices[instance][i][j] = new_spin

def average_magnetization(m, lattices, n, N, M):
    total_sites = N * M
    for instance in range(n):
        s_sum = 0
        for i in range(N):
            for j in range(M):
                s_sum += lattices[instance][i][j]
        m[instance] = float(s_sum) / total_sites

# NOTE: The filtering option has been removed; the dataset is returned as generated.

def generate_dataset(n, Steps, tmax, N=25, M=25, J=1.0, D=2.0):
    T = [0.0] * 10000
    m = [0.0] * 10000
    Plus = [0] * N
    Minus = [0] * N
    boundaries(Plus, Minus, N)
    assign_temperatures(T, n, tmax)
    lattices = []
    for _ in range(n):
        config = [[0 for _ in range(M)] for _ in range(N)]
        lattices.append(config)
    fill_lattices(lattices, n, N, M)
    metropolis(lattices, Plus, Minus, T, n, N, M, Steps, J, D)
    average_magnetization(m, lattices, n, N, M)
    data = np.array([np.array(config).flatten().astype(float) for config in lattices])
    return np.array(T[:n]), np.array(m[:n]), data, lattices

def generate_fixed_dataset(n, Steps, T_fixed, N=25, M=25, J=1.0, D=2.0):
    T = [T_fixed] * n
    m = [0.0] * n
    Plus = [0] * N
    Minus = [0] * N
    boundaries(Plus, Minus, N)
    lattices = []
    for _ in range(n):
        config = [[0 for _ in range(M)] for _ in range(N)]
        lattices.append(config)
    fill_lattices(lattices, n, N, M)
    metropolis(lattices, Plus, Minus, T, n, N, M, Steps, J, D)
    average_magnetization(m, lattices, n, N, M)
    data = np.array([np.array(config).flatten().astype(float) for config in lattices])
    return np.array(T), np.array(m), data

# ------------------------------
# SOM SECTION: CLASSES AND FUNCTIONS FOR BATCH TRAINING
# (The training operates on vectors of dimension 625)
# ------------------------------

NUM_NEURONS = 225   # 15x15
DIM_WEIGHTS = 625

class Neuron:
    def __init__(self, x, y, weights):
        self.x = x
        self.y = y
        self.weights = weights[:]  
        self.distance = 0.0
        self.flag = 0

class Signal:
    def __init__(self, ising):
        self.ising = ising[:]  

class BestUnitMatch:
    def __init__(self, X=0, Y=0, weights=None):
        self.X = X
        self.Y = Y
        self.weights = weights[:] if weights is not None else [0.0]*DIM_WEIGHTS

def spin_som():
    return -1.0 if random.randrange(2)==0 else 1.0

def init_neurons():
    neurons = []
    for i in range(15):
        for j in range(15):
            weights = [spin_som() for _ in range(DIM_WEIGHTS)]
            neurons.append(Neuron(x=i, y=j, weights=weights))
    return neurons

def best_match(neurons, input_signal):
    n = len(neurons)
    for neuron in neurons:
        diff_sq_sum = sum((inp - w)**2 for inp, w in zip(input_signal.ising, neuron.weights))
        neuron.distance = math.sqrt(diff_sq_sum)
    bingo = random.randrange(n)
    for i in range(n):
        if neurons[i].distance < neurons[bingo].distance:
            bingo = i
    best_neuron = neurons[bingo]
    return BestUnitMatch(X=best_neuron.x, Y=best_neuron.y, weights=best_neuron.weights)

def radius(neuron, bmu):
    L = 15
    a = min((neuron.x - bmu.X)**2, (abs(neuron.x - bmu.X - L))**2)
    b = min((neuron.y - bmu.Y)**2, (abs(neuron.y - bmu.Y - L))**2)
    return math.sqrt(a + b)

def neighborhood(neuron, bmu, s):
    r_sq = radius(neuron, bmu)**2
    return math.exp(-r_sq/(2*s*s))

def train_SOM_batch(training_data, s0=1.0, initial_step=7):
    n_samples = training_data.shape[0]
    signals = [Signal(ising=list(training_data[i])) for i in range(n_samples)]
    neurons = init_neurons()
    bmu_list = [None]*n_samples
    h_matrix = [[0.0 for _ in range(NUM_NEURONS)] for _ in range(n_samples)]
    
    step = initial_step
    s = step * s0 + 0.5
    print("Batch SOM training initialized.")
    while step > 3:
        for i in range(n_samples):
            bmu_list[i] = best_match(neurons, signals[i])
        for i in range(n_samples):
            for j in range(NUM_NEURONS):
                h_matrix[i][j] = neighborhood(neurons[j], bmu_list[i], s)
        for weight_index in range(DIM_WEIGHTS):
            for neuron_index in range(NUM_NEURONS):
                sum_h = sum(h_matrix[k][neuron_index] for k in range(n_samples))
                if sum_h == 0:
                    new_weight = 0
                else:
                    sum_h_ising = sum(h_matrix[k][neuron_index]*signals[k].ising[weight_index] for k in range(n_samples))
                    new_weight = sum_h_ising/sum_h
                neurons[neuron_index].weights[weight_index] = new_weight
        step -= 1
        s = step * s0 + 0.5
        print(f"Batch iteration completed, current step = {step}")
    print("Batch SOM training completed.")
    som_weights = np.empty((15,15, DIM_WEIGHTS))
    for neuron in neurons:
        som_weights[neuron.x, neuron.y, :] = neuron.weights
    return som_weights

# ------------------------------
# TEST SIGNALS: GENERATING FIXED-TEMPERATURE TEST SIGNALS
# ------------------------------

def get_fixed_temperatures():
    """
    Manually compile the list of 170 fixed temperatures.
    For example:
      - from 0 to 0.3 in steps of 0.1,
      - from 0.3 to 0.5 with 41 values (step ≈0.005),
      - from 0.5 to 5 in steps of 0.1,
      - from 5 to 10 in steps of 0.2,
      - from 10 to 20 in steps of 0.5.
    Modify the gradients as needed.
    """
    temps1 = np.arange(0, 0.3+0.1, 0.1)        # 0 to 0.3
    temps2 = np.linspace(0.3, 0.5, num=41)       # 0.3 to 0.5 (41 values, step ~0.005)
    temps3 = np.arange(0.5+0.1, 5+0.1, 0.1)       # 0.6 to 5, step 0.1
    temps4 = np.arange(5+0.2, 10+0.2, 0.2)        # 5.2 to 10, step 0.2
    temps5 = np.arange(10+0.5, 20+0.5, 0.5)       # 10.5 to 20, step 0.5
    fixed_temps = np.concatenate([temps1, temps2, temps3, temps4, temps5])
    return fixed_temps

def generate_test_signals_fixed(n_conf_per_signal, Steps, N=25, M=25, J=1.0, D=2.0):
    fixed_temps = get_fixed_temperatures()
    test_signals = []
    for T_fixed in fixed_temps:
        _, _, data = generate_fixed_dataset(n_conf_per_signal, Steps, T_fixed, N, M, J, D)
        test_signals.append(data)
    return np.array(fixed_temps), test_signals

# ------------------------------
# PHASE 4: NEURAL ACTIVITY EVALUATION PER SIGNAL
# ------------------------------

def evaluate_signal(som_weights, signal_data, map_height=15, map_width=15):
    n_conf = signal_data.shape[0]
    bmu_set = set()
    def find_bmu(x, weights):
        diff = weights - x
        dist_sq = np.sum(diff**2, axis=2)
        return np.unravel_index(np.argmin(dist_sq, axis=None), dist_sq.shape)
    for s in range(n_conf):
        bmu = find_bmu(signal_data[s], som_weights)
        i, j = bmu
        bmu_set.add(i * map_width + j)
    return len(bmu_set)

# ------------------------------
# MAIN
# ------------------------------

def main():
    intro()
    random.seed(int(time.time()))
    
    # Phase 1: Generate training dataset for Ising spin-1 (D=2)
    print("=== Phase 1: Generating training dataset for Ising spin-1 ===")
    n_train = 10000   # e.g., 10,000 configurations
    Steps = 100              # number of sweeps per configuration
    J = 1.0
    D = 2.0                # Set D=2 to study the regime beyond the tricritical point (T_c ≈ 0.4)
    tmax = 8               # training temperature range [0, tmax]
    T_train, m_train, training_data, train_lattices = generate_dataset(n_train, Steps, tmax, N=25, M=25, J=J, D=D)
    print(f"Training dataset generated with {n_train} configurations.")
    
    # Scatter plot: Average magnetization vs. Temperature (Training)
    plt.figure(figsize=(8,6))
    plt.scatter(T_train, m_train, c='blue', marker='o', s=5, alpha=0.7)
    plt.xlabel("Temperature T")
    plt.ylabel("Magnetization m")
    plt.title("Training data")
    plt.grid(True)
    plt.show()
    
    # Phase 2: Train the SOM using the batch method
    print("=== Phase 2: Training the SOM (Batch Method) ===")
    som_weights = train_SOM_batch(training_data, s0=1.0, initial_step=7)
    
    # Phase 3: Generate fixed-temperature test signals
    print("=== Phase 3: Generating test signals at fixed temperatures ===")
    n_conf_per_signal = 1000
    T_test, test_signals = generate_test_signals_fixed(n_conf_per_signal, Steps, N=25, M=25, J=J, D=D)
    print(f"Generated {len(T_test)} test signals (each with up to {n_conf_per_signal} configurations).")
    
    # Phase 4: Evaluate neural activity for each test signal
    print("=== Phase 4: Evaluating neural activity per signal ===")
    activated_neurons = []
    for signal in test_signals:
        count = evaluate_signal(som_weights, signal, map_height=15, map_width=15)
        activated_neurons.append(count)
    activated_neurons = np.array(activated_neurons)
    
    # Compute fraction of activated neurons (activated neurons / total neurons)
    fraction_activated = activated_neurons / 225.0

    # Sort the signals by temperature for plotting
    indices = np.argsort(T_test)
    T_test_sorted = T_test[indices]
    fraction_sorted = fraction_activated[indices]

    plt.figure(figsize=(8,6))
    plt.plot(T_test_sorted, fraction_sorted, marker='o', linestyle='-')
    plt.xlabel("Signal temperature")
    plt.ylabel("Fraction of activated neurons")
    plt.title("Neural activity")
    plt.grid(True)
    plt.show()

if __name__ == "__main__":
    main()
